import json
import time
import os
from datetime import datetime
from gnews import GNews
from dateutil import parser as date_parser

# --- 1. è¨­å®šæª”æ¡ˆè·¯å¾‘ ---
P1_JSON_PATH = './temp_data/prompt1_json/2024_1102_p1.json'  # json1è¦æœ‰keyword
OUTPUT_DIR = './news_search/news_output/'

# --- 2. è®€å–ä¸Šå¸‚å…¬å¸å°ç…§è¡¨ ---
print("æ­£åœ¨è®€å–ä¸Šå¸‚å…¬å¸ä»£è™Ÿå°ç…§è¡¨...")
stock_map = {}
try:
    with open('./static/data/tw_listed_companies.json', 'r', encoding='utf-8') as f:
        companies = json.load(f)
        for company in companies:
            code = company.get('å…¬å¸ä»£è™Ÿ')
            name = company.get('å…¬å¸ç°¡ç¨±', company.get('å…¬å¸åç¨±', ''))
            if code:
                stock_map[code] = name
    print(f"âœ“ å·²è¼‰å…¥ {len(stock_map)} å®¶ä¸Šå¸‚å…¬å¸å°ç…§è³‡æ–™")
except FileNotFoundError:
    print("âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°ä¸Šå¸‚å…¬å¸å°ç…§è¡¨æª”æ¡ˆ './static/data/tw_listed_companies.json'")
    print("è«‹ç¢ºèªæª”æ¡ˆè·¯å¾‘æ˜¯å¦æ­£ç¢ºã€‚")
    exit(1)
except Exception as e:
    print(f"âŒ è®€å–å°ç…§è¡¨å¤±æ•—: {e}")
    exit(1)

# --- 3. è®€å–è¼¸å…¥æª”æ¡ˆ ---
print("æ­£åœ¨è®€å–è¼¸å…¥æª”æ¡ˆ...")

# è®€å– P1 keyword JSON
with open(P1_JSON_PATH, 'r', encoding='utf-8') as f:
    p1_data_list = json.load(f)
print(f"âœ“ å·²è¼‰å…¥ {len(p1_data_list)} ç­† P1 é—œéµå­—è³‡æ–™")

# --- 4. å»ºç«‹è¼¸å‡ºç›®éŒ„ ---
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)
    print(f"âœ“ å·²å»ºç«‹è¼¸å‡ºç›®éŒ„: {OUTPUT_DIR}")

# --- 5. æ—¥æœŸé©—è­‰å‡½æ•¸ ---
def is_date_in_year(date_str, target_year):
    """
    æª¢æŸ¥æ–°èç™¼å¸ƒæ—¥æœŸæ˜¯å¦åœ¨ç›®æ¨™å¹´ä»½å…§
    :param date_str: æ–°èç™¼å¸ƒæ—¥æœŸå­—ä¸²
    :param target_year: ç›®æ¨™å¹´ä»½ (int)
    :return: True å¦‚æœåœ¨ç›®æ¨™å¹´ä»½å…§ï¼Œå¦å‰‡ False
    """
    if not date_str:
        return False
    
    try:
        # è§£ææ—¥æœŸå­—ä¸²
        parsed_date = date_parser.parse(date_str)
        # æª¢æŸ¥å¹´ä»½æ˜¯å¦åŒ¹é…
        return parsed_date.year == target_year
    except Exception as e:
        # å¦‚æœç„¡æ³•è§£ææ—¥æœŸï¼Œä¿å®ˆèµ·è¦‹æ’é™¤è©²æ–°è
        print(f"  âš ï¸  ç„¡æ³•è§£ææ—¥æœŸ: {date_str}")
        return False

# --- 6. åˆå§‹åŒ–çµæœå®¹å™¨ ---
# ç°¡åŒ–è¼¸å‡ºæ ¼å¼ï¼šåªä¿ç•™å¿…è¦æ¬„ä½
all_news_articles = []
news_id_counter = 1

# --- 6. åŸ·è¡Œæœå°‹ä¸»ç¨‹åº ---
print(f"\né–‹å§‹åŸ·è¡Œå¤–éƒ¨æŸ¥æ ¸ï¼Œå…± {len(p1_data_list)} ç­†è³‡æ–™...\n")
print("=" * 60)

for idx, item in enumerate(p1_data_list, 1):
    # å–å¾—åŸºæœ¬è³‡è¨Š
    stock_code = item.get("company")
    company_name = stock_map.get(stock_code, stock_code)
    topic = item.get("sasb_topic")
    year_str = item.get("year")
    esg_category = item.get("esg_category")
    risk_score = item.get("risk_score")
    report_claim = item.get("report_claim", "")
    
    print(f"[{idx}/{len(p1_data_list)}] æŸ¥æ ¸: {company_name} ({stock_code}) - {topic} ({year_str})")
    
    # è¨­å®š GNews æ™‚é–“ç¯„åœ
    try:
        target_year = int(year_str)
        # è¨­å®šæœç´¢çµæœæ•¸é‡
        google_news = GNews(language='zh-TW', country='TW', max_results=10)
        google_news.start_date = (target_year, 1, 1)
        google_news.end_date = (target_year, 12, 31)
        date_range = f"{target_year}0101~{target_year}1231"
        print(f"  ğŸ“… æœç´¢ç¯„åœ: {date_range}")
    except ValueError:
        print(f"  âš ï¸  æ—¥æœŸæ ¼å¼éŒ¯èª¤ï¼Œè·³éæ­¤ç­†")
        continue
    
    # å–å¾—é—œéµå­—
    key_word = item.get("key_word", "")
    
    if key_word:
        # === æœå°‹ç­–ç•¥ï¼ˆkeywordå·²åŒ…å«å…¬å¸åç¨±ï¼‰ ===
        # ç­–ç•¥1: ä½¿ç”¨å®Œæ•´é—œéµå­—ï¼ˆå·²å«å…¬å¸åç¨±ï¼‰
        query = key_word
        
        print(f"  ğŸ” æœå°‹ç­–ç•¥1: {query}")
        
        try:
            # åŸ·è¡Œæœå°‹ç­–ç•¥1
            news_results = google_news.get_news(query)
            
            # å¦‚æœçµæœå¤ªå°‘ï¼Œå˜—è©¦ç­–ç•¥2ï¼šç°¡åŒ–é—œéµå­—ï¼ˆå–å‰3å€‹è©ï¼‰
            if not news_results or len(news_results) < 3:
                key_words_list = key_word.split()
                if len(key_words_list) >= 3:
                    # å–å‰é¢è¼ƒé‡è¦çš„é—œéµå­—
                    query2 = ' '.join(key_words_list[:3])
                    print(f"  ğŸ” æœå°‹ç­–ç•¥2: {query2}")
                    news_results2 = google_news.get_news(query2)
                    if news_results2 and len(news_results2) > len(news_results or []):
                        news_results = news_results2
                        query = query2
            
            # å¦‚æœé‚„æ˜¯æ²’æœ‰ï¼Œå˜—è©¦ç­–ç•¥3ï¼šå…¬å¸åç¨± + ä¸»é¡Œ
            if not news_results or len(news_results) < 2:
                query3 = f'{company_name} {topic}'
                print(f"  ğŸ” æœå°‹ç­–ç•¥3: {query3}")
                news_results3 = google_news.get_news(query3)
                if news_results3 and len(news_results3) > len(news_results or []):
                    news_results = news_results3
                    query = query3
            
            if news_results:
                print(f"  ğŸ“° å…±æ‰¾åˆ° {len(news_results)} å‰‡æ–°èï¼Œé–‹å§‹éæ¿¾...")
                # éæ¿¾ï¼šåªä¿ç•™ç›®æ¨™å¹´ä»½å…§çš„æ–°è
                filtered_news = []
                filtered_out_count = 0
                
                for news in news_results:
                    published_date = news.get('published date', '')
                    
                    # æª¢æŸ¥æ—¥æœŸæ˜¯å¦åœ¨ç›®æ¨™å¹´ä»½å…§
                    if is_date_in_year(published_date, target_year):
                        # æ·»åŠ åˆ°ç¸½çµæœåˆ—è¡¨ï¼ŒåŒ…å«æµæ°´è™Ÿå’Œå®Œæ•´è³‡è¨Š
                        all_news_articles.append({
                            "news_id": news_id_counter,
                            "stock_code": stock_code,
                            "company_name": company_name,
                            "sasb_topic": topic,
                            "search_query": query,
                            "title": news.get('title', ''),
                            "url": news.get('url', ''),
                            "published_date": published_date,
                            "publisher": news.get('publisher', {}).get('title', '') if isinstance(news.get('publisher'), dict) else '',
                        })
                        news_id_counter += 1
                        filtered_news.append(news)  # ç”¨æ–¼è¨ˆæ•¸
                    else:
                        filtered_out_count += 1
                
                if filtered_news:
                    print(f"  âœ“ éæ¿¾å¾Œä¿ç•™ {len(filtered_news)} å‰‡ {target_year} å¹´æ–°èï¼ˆæ’é™¤ {filtered_out_count} å‰‡ï¼‰")
                else:
                    print(f"  âš ï¸  æ‰¾åˆ° {len(news_results)} å‰‡æ–°èï¼Œä½†å…¨éƒ¨ä¸åœ¨ {target_year} å¹´ç¯„åœå…§")
            else:
                print("  âŒ ç„¡ç›¸é—œæ–°è")
                
        except Exception as e:
            print(f"  âŒ æœå°‹å¤±æ•—: {str(e)}")
            import traceback
            print(f"  è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
        
        # é¿å…è«‹æ±‚å¤ªå¿«è¢«æ“‹
        time.sleep(2)
        
    else:
        print(f"  âš ï¸  è­¦å‘Š: æ­¤ç­†è³‡æ–™æœªåŒ…å« key_word æ¬„ä½")
    
    print("-" * 60)

# --- 7. å„²å­˜çµæœ ---
output_filename = os.path.join(OUTPUT_DIR, f'{year}_{stock_code}_news_results_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json')

with open(output_filename, 'w', encoding='utf-8') as f:
    json.dump(all_news_articles, f, ensure_ascii=False, indent=2)

print("\n" + "=" * 60)
print(f"âœ… æŸ¥æ ¸å®Œæˆï¼")
print(f"ğŸ“ çµæœå·²å„²å­˜è‡³: {output_filename}")
print(f"ğŸ“Š çµ±è¨ˆ:")
print(f"   - ç¸½æŸ¥æ ¸ç­†æ•¸: {len(p1_data_list)}")
print(f"   - æ–°èç¸½æ•¸: {len(all_news_articles)}")
print("=" * 60)