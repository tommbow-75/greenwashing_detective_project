import json
import os
import requests
from dotenv import load_dotenv
from perplexity import Perplexity
import time
import glob

load_dotenv()

PROMPT_TEMPLATE = """
æª”æ¡ˆç‚ºè©²å…¬å¸æ°¸çºŒå ±å‘Šæ›¸çš„è²æ˜èˆ‡é¢¨éšªåˆ†æ•¸,ä»¥ä¸‹ç¨±ç‚º"åŸæª”"
è«‹å¹«æˆ‘é‡å°åŸæª”ä¼æ¥­è²ç¨±,é€²è¡Œ"å¤–éƒ¨æ–°èæ¯”å°èˆ‡é¢¨éšªèª¿æ•´"

è¦æ±‚:
1. æ¯”å°åŸæª”ä¼æ¥­è²ç¨± èˆ‡ 'å¤–éƒ¨æ–°èå ±å°ã€ç¬¬ä¸‰æ–¹è©•ç´šã€æˆ–ç”¢æ¥­è² é¢/æ­£é¢è³‡è¨Šã€å¯¦éš›è£ç½°ç´€éŒ„(ä¸è¦åƒç…§è©²å…¬å¸è‡ªå·±å®˜ç¶²çš„æ–°è)'
2. å¤–éƒ¨è³‡è¨Šå¹´ä»½å¿…é ˆèˆ‡åŸæª”å…§å¹´ä»½ä¸€è‡´,ä¸éœ€è¦ä»¥æœªä¾†ä¸€å¹´çš„äº‹ä»¶å»å›æ¨æœ¬å¹´ä»½çš„çœŸå¯¦æ€§
3. é¢¨éšªèª¿æ•´é‚è¼¯ä¾ç…§msci_flag.json
4. ä½¿ç”¨éˆå¼æ€è€ƒ,å…ˆåˆ¤æ–·ã€Œå—å½±éŸ¿äººæ•¸ã€ã€ã€Œæ˜¯å¦æ¶‰åŠæ­»äº¡ã€ã€ã€Œæ˜¯å¦é•åæ³•è¦ã€,æœ€å¾Œå†è¼¸å‡ºæ——è™Ÿ
5. red=-4, orange=-2, yellow=-1, green=0
6. ç‰¹åˆ¥æ³¨æ„ã€Œæ©˜æ——ã€èˆ‡ã€Œç´…æ——ã€çš„é‚Šç•Œã€‚redé€šå¸¸æ¶‰åŠã€Œç³»çµ±æ€§ã€é•·æœŸã€ä¸å¯é€†ã€;orangeå‰‡å¤šç‚ºã€Œå¤§è¦æ¨¡ã€åš´é‡ã€ä½†å·²é–‹å§‹ä¿®å¾©ã€
7. è‹¥åŸæª”è¼¸å…¥Xç­†è²ç¨±,å°±è¦è¼¸å‡ºXç­†çµæœ
8. æœ€ä½åˆ†ç‚º0åˆ†

è¼¸å‡ºJSONæ ¼å¼(åš´æ ¼åŸ·è¡Œ),æ¯ç­†è³‡æ–™åŒ…å«:
- company: å…¬å¸è‚¡ç¥¨ä»£ç¢¼
- year: å¹´ä»½
- original_claim: åŸå§‹è²æ˜
- original_score: åŸå§‹åˆ†æ•¸
- external_evidence: å¤–éƒ¨æ–°èè³‡æ–™
- external_evidence_url: å¤–éƒ¨æ–°èè³‡æ–™é€£çµ
- consistency_status: å¤–éƒ¨é©—è­‰çµæœ(ä¸€è‡´/éƒ¨åˆ†ä¸€è‡´/ä¸ä¸€è‡´)
- MSCI_flag: é¢¨éšªåˆ†ç´š(red/orange/yellow/green)
- adjustment_score: èª¿æ•´å¾Œåˆ†æ•¸
- reasoning: èª¿æ•´ç†ç”±

ã€åŸæª”è³‡æ–™ã€‘
{data}
"""

def analyze_with_perplexity(data):
    """ä½¿ç”¨ Perplexity é€²è¡Œ ESG é¢¨éšªåˆ†æ"""
    try:
        perplexity_client = Perplexity(api_key=os.environ.get("PERPLEXITY_API_KEY"))
        
        # å°‡è³‡æ–™è½‰æ›ç‚º JSON å­—ä¸²ä¸¦æ•´åˆåˆ° prompt
        data_str = json.dumps(data, ensure_ascii=False, indent=2)
        prompt = PROMPT_TEMPLATE.format(data=data_str)
        
        print("ğŸ” æ­£åœ¨å‘¼å« Perplexity API é€²è¡Œåˆ†æ...")
        
        response = perplexity_client.chat.completions.create(
            model="sonar",
            messages=[{"role": "user", "content": prompt}]
        )
        
        # é¡¯ç¤º token ä½¿ç”¨é‡
        usage = response.usage
        print(f"ğŸ“Š Perplexity API ä½¿ç”¨é‡:")
        print(f"  - Input tokens: {usage.prompt_tokens}")
        print(f"  - Output tokens: {usage.completion_tokens}")
        print(f"  - Total tokens: {usage.total_tokens}")
        
        # è§£æå›æ‡‰å…§å®¹
        content = response.choices[0].message.content
        
        # æ¸…ç† JSON æ ¼å¼ (ç§»é™¤å¯èƒ½çš„ markdown æ¨™è¨˜)
        clean_json = content.replace('```json', '').replace('```', '').strip()
        
        # è§£æ JSON
        result = json.loads(clean_json)
        
        return result if isinstance(result, list) else [result]
        
    except json.JSONDecodeError as e:
        print(f"âŒ JSON è§£æéŒ¯èª¤: {e}")
        print(f"åŸå§‹å›æ‡‰å…§å®¹:\n{content}")
        return None
    except Exception as e:
        print(f"âŒ Perplexity API éŒ¯èª¤: {e}")
        return None

def process_json_file(input_file, output_file):
    """è™•ç† ESG åˆ†ææµç¨‹"""
    print(f"ğŸ“– è®€å–æª”æ¡ˆ: {input_file}")
    
    # è®€å–è¼¸å…¥æª”æ¡ˆ
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {input_file}")
        return
    except json.JSONDecodeError:
        print(f"âŒ JSON æ ¼å¼éŒ¯èª¤: {input_file}")
        return
    
    total = len(data)
    print(f"âœ… æˆåŠŸè®€å– {total} ç­†è³‡æ–™")
    
    # ä½¿ç”¨ Perplexity é€²è¡Œåˆ†æ
    analysis_start = time.perf_counter()
    results = analyze_with_perplexity(data)
    analysis_duration = time.perf_counter() - analysis_start
    
    if results is None:
        print("âŒ åˆ†æå¤±æ•—,ç„¡æ³•ç”¢ç”Ÿçµæœ")
        return
    
    print(f"â±ï¸ åˆ†æè€—æ™‚: {analysis_duration:.2f} ç§’")
    print(f"âœ… æˆåŠŸåˆ†æ {len(results)} ç­†è³‡æ–™")
    
    # å„²å­˜çµæœ
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"ğŸ“ çµæœå·²å„²å­˜è‡³: {output_file}")
    except Exception as e:
        print(f"âŒ å„²å­˜æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return
    
    # é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
    print("\nğŸ“Š åˆ†æçµæœçµ±è¨ˆ:")
    flag_counts = {}
    for item in results:
        flag = item.get('MSCI_flag', 'unknown')
        flag_counts[flag] = flag_counts.get(flag, 0) + 1
    
    for flag, count in sorted(flag_counts.items()):
        print(f"  - {flag}: {count} ç­†")


def get_latest_file(folder_path, extension=".json"):
    """è‡ªå‹•åµæ¸¬è³‡æ–™å¤¾ä¸­æœ€æ–°çš„ JSON æª”æ¡ˆ"""
    files = glob.glob(os.path.join(folder_path, f"*{extension}"))
    return max(files, key=os.path.getmtime) if files else None


if __name__ == "__main__":
    # è¨˜éŒ„é–‹å§‹æ™‚é–“
    script_start_time = time.perf_counter()
    
    # è¨­å®šæª”æ¡ˆè·¯å¾‘
    INPUT_FOLDER = "./temp_data/prompt1_json"
    OUTPUT_FOLDER = "./temp_data/prompt2_json"
    
    # ç¢ºä¿è¼¸å‡ºè³‡æ–™å¤¾å­˜åœ¨
    os.makedirs(OUTPUT_FOLDER, exist_ok=True)
    
    # 2. æŠ“å–æœ€æ–°æª”æ¡ˆ
    latest_path = get_latest_file(INPUT_FOLDER)

    if latest_path:
        # 3. è®€å–å…§å®¹ä»¥ç²å–å‹•æ…‹å‘½åè³‡è¨Š
        try:
            with open(latest_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # å–å¾—å…¬å¸èˆ‡å¹´ä»½ (ç§»é™¤ç©ºæ ¼ä»¥é˜²æª”åå‡ºéŒ¯)
            first_item = data[0] if isinstance(data, list) else data
            company = str(first_item.get("company", "Unknown")).replace(" ", "")
            year = str(first_item.get("year", "Unknown")).replace(" ", "")

            # 4. ç²¾ç°¡å®šç¾©è¼¸å‡ºè·¯å¾‘
            # ç›´æ¥åœ¨å‘¼å«å‡½å¼æ™‚çµ„åˆè·¯å¾‘èˆ‡æª”å
            output_file = f"{OUTPUT_FOLDER}/{year}_{company}_P2.json"

            # 5. åŸ·è¡Œæ ¸å¿ƒé©—è­‰é‚è¼¯
            process_json_file(latest_path, output_file)

        except Exception as e:
            print(f"âŒ è§£ææª”æ¡ˆå…§å®¹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

        # (time-2) è¨ˆç®—ç¸½è€—æ™‚
        total_duration = time.perf_counter() - script_start_time
        print(f"â±ï¸ åŸ·è¡Œç¸½è€—æ™‚: {total_duration:.2f} ç§’")    
